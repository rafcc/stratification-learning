---
#
# By default, content added below the "---" mark will appear in the home page
# between the top bar and the list of recent posts.
# To change the home page layout, edit the _layouts/home.html file.
# See: https://jekyllrb.com/docs/themes/#overriding-theme-defaults
#
layout: page
---

<h1>Stratification Learning</h1>

## What is Stratification Learning?

_Stratification learning (SL)_ is a new machine learning paradigm developed in RIKEN AIP-FUJITSU Collaboration Center (RAFCC), a leading research institute of artificial intelligence in Japan.
While the classical manifold learning assumes that high dimensional data are distributed around a low dimensional manifold, SL assumes that the data are stratified according to some underlying _stratified space_, which is a composite of manifolds of varying dimensions.
By exploiting such a geometric structure, we can achieve an unprecedentedly efficient learning!

This page provides published papers of SL and source code for reproducing experiments therein. 

## Refereed Papers

1. Ken Kobayashi, Naoki Hamada, Akiyoshi Sannai, Akinori Tanaka, Kenich Bannai and Masashi Sugiyama: "Bézier Simplex Fitting: Describing Pareto Fronts of Simplicial Problems with Small Samples in Multi-Objective Optimization," in Proceedings of the 33rd AAAI Conference on Artificial Intelligence (AAAI-19), 2304-2313 (2019).
    - [paper](https://doi.org/10.1609/aaai.v33i01.33012304)
    - [code](https://github.com/rafcc/aaai-19.2786)
    - [supplements](https://arxiv.org/abs/1812.05222)
1. Akinori Tanaka, Akiyoshi Sannai, Ken Kobayashi and Naoki Hamada: "Asymptotic Risk of Bézier Simplex Fitting," in Proceedings of the 34th AAAI Conference on Artificial Intelligence (AAAI-20), in press.
    - [code](https://github.com/rafcc/aaai-20.1534)
    - [arxiv](https://arxiv.org/abs/1906.06924)

## Tools
- under preparation...
